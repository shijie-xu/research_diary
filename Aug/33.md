#### [Back to the Drawing Board: Revisiting the Design of Optimal Location Privacy-preserving Mechanisms](https://arxiv.org/pdf/1705.08779.pdf)

> to avoid "bad" choices, we argue that the search for optimal mechanisms must be guided by complementary criteria; two example auxiliary metrics: the conditional entropy & the worst-case quality loss

#### Contribution

- a theoretical characterization of optimal location privacy-preserving mechanisms
- provide algorithms to efficiently design mechanisms based on criteria other than the adversary's error
- evaluation on two real location datasets

#### System model

- $\pi(x)$ denotes the prior prob. that a user in the population queries

- Average Loss: $\bar{Q}(f,\pi)=\sum_{x\in X}\int_{\mathbb{R}^2}\pi(x)f(z|x) d_Q(x,z)dz$
- Worst-case Loss: $Q^+(f,\pi)=\max_{x,z,\pi(x)>0,f(z|x)>0}d_Q(x,z)$
- Average Error
- Conditional Entropy

#### Implementation

- Conditional Entropy
  - compute the prob. mass function of each output: $P_Z(z)=\sum_{x\in X}\pi(x)p(z|x)$
  - update the mechanism as $p(z|x)=P_Z(z)e^{-b d_Q(x,z)}$
  - normalization
  - repeat above steps until prob. $p(z|x)$ is below a threshold'
- Worst-case Quality



> We have proven that there is more than one optimal protection mechanism in terms of maximizing the average adversary error for a given average quality loss